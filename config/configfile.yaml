# This config file is used to store the configuration of the Orochi pipeline.
# For each parameter, we've provided a brief description of what it does and an example value. Please modify the values as needed.


## STARTING POINT
# The path to the sample sheet (TSV format) that contains the sample information.
# The sample sheet should contain the following columns: SampleID, Fastq1, Fastq2, Group, and Condition.
samples: "/lustre/BIF/nobackup/he068/Tools/orochi/config/tinto.tsv"

# The path to the output directory.
outdir: "/lustre/BIF/nobackup/he068/Projects/0-EXPLORA/data/orochi1"

# The path to the temporary directory.
tmpdir: "/tmp"

# The default number of threads to use for each rule.
threads: 32

# The maximum memory to be used by the pipeline in MB. (So 1GB = 1000MB, 1TB = 1000000MB)
max_mem: 1000000

## QUALITY CONTROL
# Max memory to be used by bbmap/bbnorm (I advise using as much as possible). Only change the number between -Xmx and g. E.g. -Xmx1500g, -Xmx400g:
bbmap_mem: '-Xmx100g'

# min_qual: The minimum quality score for trimming.
min_qual: 30

# min_length: The minimum length of the reads after trimming.
min_length: 150

# host_removal: Default: True. If True, host removal will be performed.
host_removal: False

# host_genome: The path to the host genome.
host_genome: "resources/data/reference/beta-vulgaris-subset.fasta"



## READ NORMALISATION
# bbmap_D: The desired kmer depth for read normalisation @Todo: rename to bbnorm, is more clear.
bbmap_D: 20



## ASSEMBLY OPTIONS
# assembly_method: The assembly method to use. Options: single_assembly (spades), coassembly (megahit).
assembly_method: coassembly

# normalize_reads: Whether to use read normalisation: Yes or No
normalize_reads: "Yes"

# sample_pooling: The sample pooling method to use. Options: supervised, unsupervised, no.
sample_pooling: no

# clustering: Chosen number of clusters. Only active if UNSUPERVISED sample pooling chosen. Type "0" if number of clusters should be calculated based on data.
clustering: 0

# assembly_threads: The number of threads to use for assembly.
assembly_threads: 32

# assembly_mem: The amount of memory to use for assembly. This is a percentage of max memory. E.g. 0.9, 0.8 etc.
megahit_mem: '0.9'

# kmers: The k-mer sizes to use for assembly.
# @Todo: this is overwritten bij --presets meta-large in megahit. Which is k 27 - 127 with steps of 10. Do something with this.
kmers: "27,37,47,57,67,77,87"

# Phyloflash database path
phyloflash_db: "/lustre/BIF/nobackup/he068/Database/phyloflash_db_v138.2"


## ANNOTATIONS
# min_contig_length: The minimum length of the contigs.
min_contig_length: 1000


## FUNCTIONAL ANNOTATION
# emapper_database: The path to the eggNOG database.
emapper_database: "/lustre/BIF/nobackup/he068/Database/eggnog_v5.0.2"

# min_contig_antismash: The minimum length of the contigs for antiSMASH analysis.
min_contig_antismash: 5000

# antismash_db: The path to the antiSMASH database.
antismash_db: "/lustre/BIF/nobackup/he068/miniforge3/envs/antismash/lib/python3.11/site-packages/antismash/databases"


## TAXONOMIC ANNOTATION
# CAT_database: The path to the CAT database. Match to chosen taxonomy_type (GTDB/NCBI)
CAT_database: "/lustre/BIF/nobackup/he068/Database/20260122_CAT_gtdb_v226/db"

# CAT_taxonomy: The path to the CAT taxonomy files. Match to chosen taxonomy_type (GTDB/NCBI)
CAT_taxonomy: "/lustre/BIF/nobackup/he068/Database/20260122_CAT_gtdb_v226/tax"

# taxonomy_type: GTDB/NCBI. NOTICE!!! CAT related databases need to match this choice.
taxonomy_type: GTDB

# CheckM2 database path. CheckM2 database v3 from https://zenodo.org/records/14897628
checkm_db: "/lustre/BIF/nobackup/he068/Database/CheckM2_database_v3/uniref100.KO.1.dmnd"